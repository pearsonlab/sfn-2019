<!doctype html>
<html>
	<head>
		<meta charset="utf-8">
		<meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no">

		<title>reveal.js</title>

		<link rel="stylesheet" href="css/reveal.css">
		<link rel="stylesheet" href="css/theme/black.css">
		<link rel="stylesheet" href="css/custom.css">

		<!-- Theme used for syntax highlighting of code -->
		<link rel="stylesheet" href="lib/css/zenburn.css">

		<!-- Printing and PDF exports -->
		<script>
			var link = document.createElement( 'link' );
			link.rel = 'stylesheet';
			link.type = 'text/css';
			link.href = window.location.search.match( /print-pdf/gi ) ? 'css/print/pdf.css' : 'css/print/paper.css';
			document.getElementsByTagName( 'head' )[0].appendChild( link );
		</script>
	</head>
	<body>
		<div class="reveal">
			<div class="slides">
				<section data-markdown>
					##Dynamic decisions and strategic repertoires in simulated multi-prey pursuit
					John Pearson

					[pearsonlab.github.io/sfn-2019](https://pearsonlab.github.io/sfn-2019)
				</section>
				<section>
					<div style="float:left; width:34%">
						<img src="https://web.duke.edu/mind/level2/faculty/pearson/assets/images/website/sam.jpg" >
						<p>Sam Yin</p>
					</div>
					<div style="float:left; width:33%">
						<img src="https://web.duke.edu/mind/level2/faculty/pearson/assets/images/website/syoo.jpg">
						<p>Michael Yoo</p>
					</div>
					<div style="float:left; width:28.5%">
						<img src="https://web.duke.edu/mind/level2/faculty/pearson/assets/images/website/hayden.jpg" >
						<p>Ben Hayden</p>
					</div>
				</section>
				<section data-background-image="https://web.duke.edu/mind/level2/faculty/pearson/assets/images/ccn2017/4f.png">
					<div style="background-color: rgba(0, 0, 0, 0.75); padding: 10px" class="fragment fade-left">
						<h3>Why natural tasks?</h3>
						<ul>
							<li class="fragment">
								Selection pressure determines function
							</li>
							<br>
							<li class="fragment">
								Study brain in normal operating regime
							</li>
							<br>
							<li class="fragment">
								Engage multiple brain systems simultaneously
							</li>
							<br>
					</div>

					<aside class="notes" data-markdown>
						- [upper left](https://thedrinkingbird.files.wordpress.com/2013/05/img_2476.jpg)
						- [upper right](http://seancrane.com/galleries/japan/) Sean Crane
						- [lower right](http://www.gettyimages.com/license/153234629): MOHD RASFAN/AFP/GettyImages
						- [lower right](https://commons.wikimedia.org/wiki/File:Baviaan2.JPG) Dick Mudde
					</aside>
				</section>
				<section data-background-image="https://web.duke.edu/mind/level2/faculty/pearson/assets/images/sfn2019/charles_pursuit.jpeg">
					<div style="background-color: rgba(0, 0, 0, 0.75); padding: 10px" class="fragment fade-left">
						<h3>Why pursuit?</h3>
						<ul>
							<li class="fragment">
								Canonical natural behavior
							</li>
							<br>
							<li class="fragment">
								Really several (looped) behaviors:
								<ul>
									<li>Target detection</li>
									<li>Target selection</li>
									<li>Strategy selection</li>
									<li>Motor planning</li>
									<li>Motor execution</li>
								</ul>
							</li>
							<br>
							<li class="fragment">
								Multiple intersecting optimal/empirical models
							</li>
							<br>
					</div>

					<aside class="notes" data-markdown>
					</aside>
				</section>
				<section>
					<h3>Simulated Multi-Prey Pursuit</h3>
					<video width="75%" align="center" controls autoplay loop src="https://web.duke.edu/mind/level2/faculty/pearson/assets/videos/penaltyshot/sess130_new.mp4" type="video/mp4">
						Your browser does not support the video tag.
					</video>
					<p class="ref">Yoo, Tu, Piantadosi, Hayden (<a href="https://www.biorxiv.org/content/10.1101/694604v1.abstract">Nat. Neuro, forthcoming</a>)</p>
					<aside class="notes" data-markdown>
					</aside>
				</section>
				<section>
					<h3>aka, Pacman</h3>
					Yoo et al. Fig 1A here
					<p class="ref">Yoo, Tu, Piantadosi, Hayden (<a href="https://www.biorxiv.org/content/10.1101/694604v1.abstract">Nat. Neuro, forthcoming</a>)</p>
				</section>
				<section>
					<h3>Modeling tactics</h3>
					Yoo et al. Fig 2A here
					<p class="ref">Yoo, Tu, Piantadosi, Hayden (<a href="https://www.biorxiv.org/content/10.1101/694604v1.abstract">Nat. Neuro, forthcoming</a>)</p>
				</section>
				<section>
					<h3>Modeling strategies</h3>
					<ul>
						<li>
							Can we go beyond kinematics?
						</li>
						<br>
						<li>
							Can we identify distinct strategies?
						</li>
						<br>
						<li>
							Can we detect changes of mind?
						</li>
					</ul>
				</section>
				<section>
					<h3>What do we want?</h3>
					<ul>
						<li>
							Capture complexities present in real data
						</li>
						<br>
						<li>
							Work in terms of interpretable constructs
						</li>
						<br>
						<li>
							Be able to generate realistic behavior
						</li>
					</ul>
				</section>
				<section>
					<h3>Penalty Shot</h3>
					<video width="70%" align="center" controls autoplay loop src="https://web.duke.edu/mind/level2/faculty/pearson/assets/videos/penaltyshot/sess130_new.mp4" type="video/mp4">
						Your browser does not support the video tag.
					</video>
					<p class="ref">Iqbal, Yin et al. (<a href="https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1006895">PLoS Comp Bio, 2019</a>)</p>
					<aside class="notes" data-markdown>
					  - two monkeys, shooter and goalie (shooter recorded)
					  - controlled by joysticks
					  - roles rotated, animals know each other
					  - repeated sessions
					  - rapidly learned, rich dynamics
					</aside>
				</section>
				<section>
					<h3>Generated trials</h3>
					<div style="width: 50%; float: left">
						<img src="https://web.duke.edu/mind/level2/faculty/pearson/assets/images/penaltyshot/paper_figs/real_traces.svg" alt="">
					</div>
					<div style="width: 50%; float: right">
						<img src="https://web.duke.edu/mind/level2/faculty/pearson/assets/images/penaltyshot/paper_figs/gen_traces.svg" alt="">
					</div>
				</section>
				<section>
					<h3>How we do it</h3>
					<ul>
						<li>
							Borrow from control theory, time series
						</li>
						<br>
						<li>
							Goals (= controller set points) evolve in time
						</li>
						<br>
						<li>
							Each strategy is a set of goal dynamics
							<ul>
								<li>
									state includes positions, velocities of all agents
								</li>
								<li>
									dynamics depend (linearly) on state
								</li>
								<li>
									&asymp; (H)HMM transitions between strategies
								</li>
								<li>
									transitions depend <i>nonlinearly</i> on state
								</li>
							</ul>
						</li>
						<br>
						<li>
							Variational Bayesian inference
						</li>
					</ul>
				</section>
				<section>
					<h3>Goal-based dynamical systems</h3>
					<video width="70%" align="center" controls autoplay loop src="https://web.duke.edu/mind/level2/faculty/pearson/assets/videos/penaltyshot/real_trial_goals.mp4" type="video/mp4">
						Your browser does not support the video tag.
					</video>
				</section>

				<section>
					<h3>How do we compare to...</h3>
					<ul>
						<li>LFADS (Pandarinath et al., 2018)</li>
						<ul>
							<li>
								Less dimension reduction, more trajectory labeling
							</li>
							<li>
								Discrete, not continuous latents
							</li>
							<li>
								Coevolving exogenous inputs
							</li>
						</ul>
						<br>
						<li>
							rSLDS (Linderman et al., 2017)
							<ul>
								<li>
									Variational, not MCMC (scale to larger data)
								</li>
								<li>
									Gumbel-softmax latents extend to <i>hierarchical</i> HMM
								</li>
							</ul>
						</li>
						<br>
					</ul>
				</section>
				<section>
					<h3>Penalty Shot</h3>
					<video width="70%" align="center" controls autoplay loop src="https://web.duke.edu/mind/level2/faculty/pearson/assets/videos/penaltyshot/sess130_new.mp4" type="video/mp4">
						Your browser does not support the video tag.
					</video>
					<p class="ref">Iqbal and Pearson (arXiv)</p>
					<aside class="notes" data-markdown>
					  - two monkeys, shooter and goalie (shooter recorded)
					  - controlled by joysticks
					  - roles rotated, animals know each other
					  - repeated sessions
					  - rapidly learned, rich dynamics
					</aside>
				</section>
				<section>
					<div style="width: 50%; float: left; text-align: left">
						<video autoplay loop  src="https://web.duke.edu/mind/level2/faculty/pearson/assets/videos/penaltyshot/real_trial.mp4" type="video/mp4" id="trace_video">
							Your browser does not support the video tag.
						</video>
						<script>
						var vid = document.getElementById("trace_video");
vid.playbackRate = 1.;
						</script>
					</div>
					<div style="width: 50%; float: right; font-size: .9em" >
						<h3>Complexity tax</h3>
						<ul style="font-size: 0.85">
							<li>each trial a different length</li>
							<li>how to average, align?</li>
							<li>need to "reduce" dynamics</li>
						</ul>
					</div>
				</section>
				<section>
					<h3>Real trials</h3>
					<div style="width: 50%; margin: auto">
						<img src="https://web.duke.edu/mind/level2/faculty/pearson/assets/images/penaltyshot/paper_figs/real_traces.svg" alt="">
					</div>
				</section>
				<section data-markdown>
					### What we want
					- ~~Joystick censoring~~
					- ~~Details of motor execution~~
					- Model of latent cognitive state
					- Capture interaction between players

				</section>
				<section data-markdown>
					### Our approach
					- Borrow from control theory, time series
					- Structured black box models (pieces make sense)
					- Neural networks for flexible fitting
				</section>
				<section>
					<h3>Modeling I</h3>
					Observed positions at each time ($y_t$):

					$$
					y_t = \begin{bmatrix}
					y_{goalie} &
					x_{puck} &
					y_{puck}
					\end{bmatrix}^\top
					$$

					<br>
					Control inputs ($u_t$) drive changes in observed positions:
					$$y_{t + 1} = y_t + v_{max} \sigma(u_t)$$

					<br>
					<b>Goal</b>: predict control inputs from trial history:
					$$u_t = F(y_{1:t})$$
				</section>
				<section>
					<h3>Modeling II</h3>
					Assumption: PID control
					$$
					u_t = u_{t-1} + L * (g_{t} - y_{t}) + \epsilon_t
					$$
					<br>
					<ul>
					  <li>linear control model: $L$</li>
					  <li>goal (set point): $g_{t}$</li>
					  <li>error signal: $e_t \equiv g_{t} - y_{t}$</li>
					  <li>observation noise: $\epsilon_t$</li>
				  </ul>
				</section>
				<section>
					<h3>Modeling III</h3>
					<h5>Goal model:</h5>
					$$
					\log p(g) = -\beta E(g|s) - \log Z \\
					E(g|s) = \sum_t \left[ \frac{1}{2} \Vert g_t - g_{t-1}\Vert^2 + U(g_t, s_t)\right]
					$$
					<br>
					<h5>How do we interpret this?</h5>
					<ul>
						<li>Goals minimize an "energy"</li>
						<li>"Kinetic" energy favors smoothness</li>
						<li>"Potential" $U$ captures player interaction</li>
					</ul>
				</section>
				<section>
					<h3>Modeling IV</h3>
					<ul>
						<li>$U$ is a problem</li>
						<li>What if $U$ were just quadratic?</li>
						<li>Model $e^U$ as a *mixture* of normals</li>
						<li>Use a Gaussian Mixture:
							<ul>
								<li>$U(g, s) = \sum_k w_k\mathcal{N}(g | \mu_k(s), \lambda_k^{-1}(s))$</li>
								<li>i.e., goal mixture depends on current state</li>
							</ul>
							</li>
					</ul>
				</section>

				</section>
				<section>
					<h3>Our model</h3>
					<img src="https://web.duke.edu/mind/level2/faculty/pearson/assets/images/penaltyshot/paper_figs/model_diagram.svg" style="background:white">
				</section>
				<section>
					<h3>Model fitting</h3>
					<h5>Variational Bayes autoencoder</h5>
					<ul>
					<li>Encoding model:</li>
						<ul>
						<li>goals: GMM</li>
						<li>latent control: PID + Gaussian noise</li>
						<li>observed control: soft censoring</li>
						</ul>
					<br>
					<li>Decoding model:</li>
						<ul>
						<li>state space model <a href="https://arxiv.org/abs/1511.07367">(Archer et al., 2015)</a></li>
						<li>= Kalman filter for linear system</li>
						</ul>
					</ul>
				</section>
				<section>
					<h3>Implementation</h3>
					<ul>
						<li>Variational Inference:
							$$
							\max_{\phi, \theta} \mathbb{E}_q[\log p_\theta(x, z)] + \mathbb{H}[q_\phi(z)] \le \log p_\theta(x)
							$$
						</li>
						<li>Stochastic Gradients:
							 $$
							 \mathbb{E}_q\left[f(z)\right] \approx f(z^*) \quad z^* \sim q_\phi(z)
							 $$
						</li>
						<li>Reparameterization Trick:
							$$
							Z = h(\epsilon, \phi) \quad \epsilon \sim \mathcal{N}(0, 1)
							$$
						</li>
						<li>Code in <a href="https://www.tensorflow.org/">TensorFlow</a> and <a href="http://edwardlib.org/">Edward</a> </li>
					</ul>
				</section>
				<!-- <section>
					<h3>It works!</h3>
					Ground truth recovery on toy data
				</section> -->
				<section>
					<h3>It fits!</h3>
					<div style="width: 50%; float: left; text-align: left">
						<img  src="https://web.duke.edu/mind/level2/faculty/pearson/assets/images/penaltyshot/pos_fit.svg" style="border: none; background: none; box-shadow: none">
						</img>
					</div>
					<div style="width: 50%; float: right; text-align: left">
						<img  src="https://web.duke.edu/mind/level2/faculty/pearson/assets/images/penaltyshot/paper_figs/single_trial_control.svg" style="border: none; background: none; box-shadow: none">
						</img>
					</div>
				</section>
				<section>
					<h3>Generated Trials</h3>
					<video width="70%" align="center" controls autoplay loop src="https://web.duke.edu/mind/level2/faculty/pearson/assets/videos/penaltyshot/gen_data.mp4" type="video/mp4">
						Your browser does not support the video tag.
					</video>
					<aside class="notes" data-markdown>
					  - Totally new behavior
					  - Captures some of the richness of original data
					  - Gives us confidence that our model is plausible
					  - *Much* stronger test than simple goodness-of-fit
					    - You can have a model that "fits" but the
						observed data are atypical of the model
					</aside>
				</section>
				<section>
					<h3>Generated trials</h3>
					<div style="width: 50%; float: left">
						<img src="https://web.duke.edu/mind/level2/faculty/pearson/assets/images/penaltyshot/paper_figs/real_traces.svg" alt="">
					</div>
					<div style="width: 50%; float: right">
						<img src="https://web.duke.edu/mind/level2/faculty/pearson/assets/images/penaltyshot/paper_figs/gen_traces.svg" alt="">
					</div>
				</section>
				<section>
					<h3>A sample trial</h3>
					<video width="70%" align="center" controls autoplay loop src="https://web.duke.edu/mind/level2/faculty/pearson/assets/videos/penaltyshot/real_trial.mp4" type="video/mp4">
						Your browser does not support the video tag.
					</video>
				</section>
				<section>
					<h3>Inferred goals</h3>
					<video width="70%" align="center" controls autoplay loop src="https://web.duke.edu/mind/level2/faculty/pearson/assets/videos/penaltyshot/real_trial_goals.mp4" type="video/mp4">
						Your browser does not support the video tag.
					</video>
				</section>
				<section>
					<h3>Potential energy function</h3>
					<video width="70%" align="center" controls autoplay loop src="https://web.duke.edu/mind/level2/faculty/pearson/assets/videos/penaltyshot/real_trial_value.mp4" type="video/mp4">
						Your browser does not support the video tag.
					</video>
				</section>
				<section data-markdown>
					###What did we do?
					- Dynamic control tasks let us leverage motor behavior to study cognitive and social decisions.
					- Structured black-box models allow us to carve behavior into interpretable pieces.
					- We inferred a value function capable of explaining behavior in terms of goals.
				</section>
				<section>
					<h2>Modeling neural data</h2>
					<img src="https://web.duke.edu/mind/level2/faculty/pearson/assets/images/penaltyshot/john_talk/spike_trajectories.svg"
					style="">
				</section>
				<section>
					<h2>Outcomes matter</h2>
					<p style="font-size: 0.5em">(Even more than they should)</p>
					<div class="wrapper" style="">
						<img class="grid-img"
						src="https://web.duke.edu/mind/level2/faculty/pearson/assets/images/penaltyshot/post_trial_firing.svg"
						style="grid-column:1/3">
						<img class="grid-img"
						src="https://web.duke.edu/mind/level2/faculty/pearson/assets/images/penaltyshot/post_trial_firing2.svg"
						style="grid-column:3/5">
					</div>
					<table>
						<tr>
							<th></th>
							<th>DMPFC</th>
							<th>DLPFC</th>
						</tr>
						<tr>
							<th>Modulated</th>
							<td>58%</td>
							<td>43%</td>
						</tr>
						<tr>
							<th>Close &ne; Easy</th>
							<td>20%</td>
							<td>18%</td>
						</tr>
					</table>
				</section>
				<section>
					<h2>Neural modeling</h2>
					We use <a href="https://www.biorxiv.org/content/biorxiv/early/2017/06/20/152884.full.pdf">LFADS</a>:
					<br>
					<div style="width: 50%; float: left; text-align: left">
						<ul>
							<li>Firing rates are linear combinations of factors</li>
							<li>Factors form a low-d dynamical system</li>
							<li>Factors shared across neurons, sessions</li>
							<li>(Sparse) regression of factors on behavior</li>
						</ul>
					</div>
					<div style="width: 50%; float: right; text-align: left">
						<img src="https://web.duke.edu/mind/level2/faculty/pearson/assets/images/penaltyshot/LFADS_cartoon.svg" style="border: none; background: white">
					</div>
				</section>
				<section>
					<h2>Neural modeling</h2>
					<img src="https://web.duke.edu/mind/level2/faculty/pearson/assets/images/penaltyshot/lfads_regressors.svg" style="border: none; background: white">
				</section>
				<section>
					<h2>What does this suggest?</h2>
					<ul>
						<li>Post-trial D(M|L)PFC reflects more than reward </li>
						<li>Within-trial firing reflects progress toward outcome</li>
						<li>Within-trial firing reflects across-trial variance
							<ul>
								<li>Strategy complexity?</li>
								<li>Decision/control difficulty?</li>
							</ul>
						</li>
					</ul>
				</section>
				<section data-markdown>
					## Future directions
				</section>
				<section>
					<h2>Individual differences</h2>
					<div class="wrapper" style="height: 800px">
						<img class="grid-img"
						src="https://web.duke.edu/mind/level2/faculty/pearson/assets/images/penaltyshot/RealTrials_21147.svg"
						style="grid-column:1/3">
						<img class="grid-img"
						src="https://web.duke.edu/mind/level2/faculty/pearson/assets/images/penaltyshot/RealTrials_21150.svg"
						style="grid-column:3/5">
						<img class="grid-img"
						src="https://web.duke.edu/mind/level2/faculty/pearson/assets/images/penaltyshot/GeneratedTrials_21147.svg"
						style="grid-column:1/3">
						<img class="grid-img"
						src="https://web.duke.edu/mind/level2/faculty/pearson/assets/images/penaltyshot/GeneratedTrials_21150.svg"
						style="grid-column:3/5">
						<p class="ref" style="grid-column:3/5; align-self: start">McDonald, Broderick, Huettel, and Pearson</p>
					</div>
				</section>
				<!-- <section>
					<h2>Focus on changepoints</h2>
					<div class="wrapper" style="">
						<img class="grid-img"
						src="https://web.duke.edu/mind/level2/faculty/pearson/assets/images/PK_gradients_kelsey/Fig1--PointySubTraj.svg"
						style="grid-column:1/3">
						<img class="grid-img"
						src="https://web.duke.edu/mind/level2/faculty/pearson/assets/images/PK_gradients_kelsey/Fig2--PointySubTrajPlusChangePoints.svg"
						style="grid-column:3/5">
					</div>
				</section>
				<section>
					<h2>Gaussian Process classification</h2>
					<div class="wrapper" style="">
						<img class="grid-img"
						src="https://web.duke.edu/mind/level2/faculty/pearson/assets/images/PK_gradients_kelsey/Fig1--PointySubTraj.svg"
						style="grid-column:1/3">
						<img class="grid-img"
						src="https://web.duke.edu/mind/level2/faculty/pearson/assets/images/PK_gradients_kelsey/Fig4--HeatmapIndivSubj.svg"
						style="grid-column:3/5">
					</div>
				</section>
				<section>
					<h2>Opponent Sensitivity</h2>
					<div class="wrapper" style="">
						<img class="grid-img"
						src="https://web.duke.edu/mind/level2/faculty/pearson/assets/images/PK_gradients_kelsey/Fig1--PointySubTraj.svg"
						style="grid-column:1/3">
						<img class="grid-img"
						src="https://web.duke.edu/mind/level2/faculty/pearson/assets/images/PK_gradients_kelsey/Fig5--TimePointGradientsforBothOpps.svg"
						style="grid-column:3/5">
					</div>
				</section> -->
				<section>
					<h2>Pacman</h2>
					<video width="90%" align="center" controls autoplay loop src="https://web.duke.edu/mind/level2/faculty/pearson/assets/videos/pacman/pac_goals.mp4" type="video/mp4" id="pacman_goals_vid">
						Your browser does not support the video tag.
					</video>
					<p class="ref">Yoo, Iqbal, Hayden, and Pearson</p>
					<script>
					var vid = document.getElementById("pacman_goals_vid");
					vid.playbackRate = 0.5;
					</script>
				</section>
				<section>
					<h2>Large-scale time series</h2>
					<div class="wrapper">
						<div style="grid-column: 1/3">
							<ul>
								<li>Intractable epilepsy</li>
								<li>~5 days 24/7 monitoring</li>
								<li>~100 ECoG sensors + A/V</li>
								<li>~100 GB per patient</li>
								<li>Deidentified data to <a href="https://aws.amazon.com/">Amazon</a></li>
								<li><a href="http://spark.apache.org/">Spark</a> for in-memory cluster computing</li>
							</ul>
						</div>
						<img class="grid-img" src="https://web.duke.edu/mind/level2/faculty/pearson/assets/images/aws-images/aws-structure.png" style="grid-column: 3/5">
					</div>
				</section>
				<section data-markdown>
					## Conclusions
					Modeling is a tool for doing the *right* experiment
					- Model single trials instead of averaging across trials
					- Data-driven firing patterns, not tuning curves
					- Population dynamics, not static single units
				</section>
				<section>
					<h2>Sponsors</h2>
					<div class="wrapper" style="height: 800px">
						<img class="grid-img"
						src="https://web.duke.edu/mind/level2/faculty/pearson/assets/images/sfn2016/bd2k_logo.png"
						style="grid-column:1/3">
						<img class="grid-img"
						src="https://web.duke.edu/mind/level2/faculty/pearson/assets/images/sfn2016/US-NIH-NIMH-Logo.svg"
						style="grid-column:3/5">
						<img class="grid-img"
						src="https://web.duke.edu/mind/level2/faculty/pearson/assets/images/misc/Nvidia_image_logo.svg"
						style="grid-column:1/3; background: white; padding: 15px">
						<img class="grid-img"
						src="https://web.duke.edu/mind/level2/faculty/pearson/assets/images/misc/Amazon_logo_plain.svg"
						style="grid-column:3/5; background: white; padding: 15px">
					</div>
				</section>
				<section>
					<div class="wrapper" style="">
						<img
						class="grid-item"
						src="https://web.duke.edu/mind/level2/faculty/pearson/assets/images/website/xin.jpg"
						style="grid-column: 1/2">
						<img
						class="grid-item"
						src="https://web.duke.edu/mind/level2/faculty/pearson/assets/images/website/shariq.jpg"
						style="grid-column: 2/3">
						<img
						class="grid-item"
						src="https://web.duke.edu/mind/level2/faculty/pearson/assets/images/website/sam.jpg"
						style="grid-column: 3/4">
						<img
						class="grid-item"
						src="https://web.duke.edu/mind/level2/faculty/pearson/assets/images/website/kelsey.jpg"
						style="grid-column: 4/5">
						<img
						class="grid-item"
						src="https://web.duke.edu/mind/level2/faculty/pearson/assets/images/website/qian.jpg"
						style="grid-column: 1/2">
						<img
						class="grid-item"
						src="https://web.duke.edu/mind/level2/faculty/pearson/assets/images/website/robert.jpg"
						style="grid-column: 2/3">
						<img
						class="grid-item"
						src="https://web.duke.edu/mind/level2/faculty/pearson/assets/images/website/athelia.jpg"
						style="grid-column: 3/4">
						<img
						class="grid-item"
						src="https://web.duke.edu/mind/level2/faculty/pearson/assets/images/website/abhishek.jpg"
						style="grid-column: 4/5">
						<!-- <img
						class="grid-item"
						src="https://web.duke.edu/mind/level2/faculty/pearson/assets/images/sfn2016/bd2k_logo.png"
						style="grid-column: 1/2"> -->
						<img
						class="grid-item"
						src="https://web.duke.edu/mind/level2/faculty/pearson/assets/images/lab_logo/plab_logo_light.svg"
						style="grid-column: 2/4">
						<!-- <img
						class="grid-item"
						src="https://web.duke.edu/mind/level2/faculty/pearson/assets/images/sfn2016/US-NIH-NIMH-Logo.svg"
						style="grid-column: 4/5"> -->
					</div>
				</section>


				<!-- extra slides -->

				<section>
					<h3>A social brain?</h3>
					<img src="https://web.duke.edu/mind/level2/faculty/pearson/assets/images/ccn2017/mars_tpj.png" style="width: 75%">
					<p class="ref">Mars et al. (PNAS 2014)</p>
				</section>
				<section>
					<img src="https://web.duke.edu/mind/level2/faculty/pearson/assets/images/ccn2017/etho_turn.png" alt="">
				</section>
				<section>
					<h3>Same behavior, different mechanisms</h3>
					<img  src="https://web.duke.edu/mind/level2/faculty/pearson/assets/images/ccn2017/marr.png" style="border: none; background: white; box-shadow: none">
					</img>
					<p class="ref">Adams, Watson, Pearson, and Platt (2012)</p>
				</section>
				<section>
					<h3>Foraging, for instance</h3>
					<img  src="https://web.duke.edu/mind/level2/faculty/pearson/assets/images/ccn2017/foraging.png" style="border: none; background: white; box-shadow: none">
					</img>
					<p class="ref">Pearson, Watson, and Platt (2014)</p>
				</section>
				<section data-background-image="https://web.duke.edu/mind/level2/faculty/pearson/assets/images/ccn2017/animatronic.jpg" data-background-size="contain">
					<blockquote cite="https://www.quora.com/What-did-Richard-Feynman-mean-when-he-said-What-I-cannot-create-I-do-not-understand", style="background-color: rgba(150, 150, 150, 0.75)">
					What I cannot create, I do not understand. &mdash; Richard Feynman
					</blockquote>
					<aside class="notes" data-markdown>
						# A note on method
						- this is what I mean by neuroengineering
							- *reverse* engineering
						- not sufficient, but necessary
						- trying to build it means understanding constraints
						- most interesting ideas in neuro theory about how *ANN*s learn

						### photo credit:
						[link](https://www.behance.net/gallery/26305123/ANIMATRONIC-AI-FOR-SPIELBERGS-EXTANT)
					</aside>
				</section>
				<section data-markdown>
					###A reverse engineering approach
					- Work "outside-in"
					- Focus on computational constraints
					- "Structured black box" modeling
				</section>
				<section>
					<h3>And in diagram form</h3>
					<img src="https://web.duke.edu/mind/level2/faculty/pearson/assets/images/nev/model_formal.svg" style="background: white">
				</section>
				<section>
					<h3>Experiment II: Parietal Cortex</h3>
					<img src="https://web.duke.edu/mind/level2/faculty/pearson/assets/images/nev/roitman.svg" style="background: white; width:80%">
					<p class="ref">Roitman and Shadlen (<em>J. Neuro.</em>, 2002)</p>
				</section>
				<section>
					<h3>Experiment III: Temporal Cortex</h3>
					<img src="https://web.duke.edu/mind/level2/faculty/pearson/assets/images/nev/imgclust_neurons.svg" style="background: white; width:100%">
				</section>
				<section>
					<h3>Predicting final target</h3>
					<div style="float: left; width: 50%">
						<img src="https://web.duke.edu/mind/level2/faculty/pearson/assets/images/penaltyshot/start_trial_end_predict.svg" alt="">
					</div>
					<div style="float: right; width: 50%">
						<img src="https://web.duke.edu/mind/level2/faculty/pearson/assets/images/penaltyshot/end_trial_end_predict.svg" alt="">
					</div>
				</section>
				<section>
					<h2>Previous state of the art</h2>
					<div class="wrapper" >
						<img class="grid-img"
						src="https://web.duke.edu/mind/level2/faculty/pearson/assets/images/penaltyshot/john_talk/dlgm_generated.png"
						style="grid-column:1/3">
						<img class="grid-img"
						src="https://web.duke.edu/mind/level2/faculty/pearson/assets/images/penaltyshot/john_talk/vrnn_generated.png"
						style="grid-column:3/5">
						<p class="ref" style="grid-column:1/3; align-self: start">Variational Autoencoder</p>
						<p class="ref" style="grid-column:3/5; align-self: start">Variational Recurrent Neural Network</p>
					</div>
				</section>
				<section>
					<h3>A potential training signal</h3>
					<div style="float: left; width: 50%">
						<img src="https://web.duke.edu/mind/level2/faculty/pearson/assets/images/penaltyshot/post_trial_firing.svg" alt="">
					</div>
					<div style="float: right; width: 50%">
						<img src="https://web.duke.edu/mind/level2/faculty/pearson/assets/images/penaltyshot/post_trial_firing2.svg" alt="">
					</div>
				</section>
				<section>
					<h3>A potential training signal</h3>
					<div style="float: left; width: 50%">
						<img src="https://web.duke.edu/mind/level2/faculty/pearson/assets/images/penaltyshot/regression_coeffs_DMPFC.svg" alt="">
					</div>
					<div style="float: right; width: 50%">
						<img src="https://web.duke.edu/mind/level2/faculty/pearson/assets/images/penaltyshot/regression_coeffs_DLPFC.svg" alt="">
					</div>
					<br>
					<table>
						<tr>
							<th></th>
							<th>DMPFC</th>
							<th>DLPFC</th>
						</tr>
						<tr>
							<th>Win > Loss</th>
							<td>33%</td>
							<td>25%</td>
						</tr>
						<tr>
							<th>Both effects</th>
							<td>15%</td>
							<td>9%</td>
						</tr>
					</table>
				</section>
				<section>
					<h3>Probing the model</h3>
					<div style="width: 50%; float: left">
						<img src="https://web.duke.edu/mind/level2/faculty/pearson/assets/images/penaltyshot/paper_figs/init_both_down.svg" alt="">
					</div>
					<div style="width: 50%; float: right">
						<img src="https://web.duke.edu/mind/level2/faculty/pearson/assets/images/penaltyshot/paper_figs/init_goalieup_balldown.svg" alt="">
					</div>
				</section>
				<section>
					<h3>Initial goal distribution</h3>
					<img src="https://web.duke.edu/mind/level2/faculty/pearson/assets/images/penaltyshot/paper_figs/g0_fit.svg" alt="">
				</section>
				<section>
					<h2>Let's view that strategically</h2>
					<div class="wrapper" style="">
						<img class="grid-img"
						src="https://web.duke.edu/mind/level2/faculty/pearson/assets/images/penaltyshot/john_talk/spike_density_converging.svg"
						style="grid-column:1/3">
						<img class="grid-img"
						src="https://web.duke.edu/mind/level2/faculty/pearson/assets/images/penaltyshot/john_talk/spike_density_diverging.svg"
						style="grid-column:3/5">
						<p style="grid-column:1/3; align-self: start">Opponents Converging</p>
						<p style="grid-column:3/5; align-self: start">Opponents Diverging</p>
					</div>
				</section>
			</div>
		</div>

		<script src="lib/js/head.min.js"></script>
		<script src="js/reveal.js"></script>

		<script>
			// More info https://github.com/hakimel/reveal.js#configuration
			Reveal.initialize({
				history: true,
				// math: {
				//         mathjax: 'https://cdn.mathjax.org/mathjax/latest/MathJax.js',
				//         config: 'TeX-AMS_HTML-full'  // See http://docs.mathjax.org/en/latest/config-files.html
			    // },

				// More info https://github.com/hakimel/reveal.js#dependencies
				dependencies: [
					{ src: 'plugin/markdown/marked.js' },
					{ src: 'plugin/markdown/markdown.js' },
					{ src: 'plugin/notes/notes.js', async: true },
					{ src: 'plugin/math/math.js', async: true },
					{ src: 'plugin/highlight/highlight.js', async: true, callback: function() { hljs.initHighlightingOnLoad(); } }
				]
			});
		</script>
	</body>
</html>
