<!doctype html>
<html>
	<head>
		<meta charset="utf-8">
		<meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no">

		<title>reveal.js</title>

		<link rel="stylesheet" href="css/reveal.css">
		<link rel="stylesheet" href="css/theme/black.css">
		<link rel="stylesheet" href="css/custom.css">

		<!-- Theme used for syntax highlighting of code -->
		<link rel="stylesheet" href="lib/css/zenburn.css">

		<!-- Printing and PDF exports -->
		<script>
			var link = document.createElement( 'link' );
			link.rel = 'stylesheet';
			link.type = 'text/css';
			link.href = window.location.search.match( /print-pdf/gi ) ? 'css/print/pdf.css' : 'css/print/paper.css';
			document.getElementsByTagName( 'head' )[0].appendChild( link );
		</script>
	</head>
	<body>
		<div class="reveal">
			<div class="slides">
				<section data-markdown>
					##Dynamic decisions and strategic repertoires in simulated multi-prey pursuit
					John Pearson

					Duke University

					[pearsonlab.github.io/sfn-2019](https://pearsonlab.github.io/sfn-2019)

					@jmxpearson
				</section>
				<section>
					<div style="float:left; width:34%">
						<img src="https://web.duke.edu/mind/level2/faculty/pearson/assets/images/website/sam.jpg" >
						<p>Sam Yin</p>
					</div>
					<div style="float:left; width:33%">
						<img src="https://web.duke.edu/mind/level2/faculty/pearson/assets/images/website/syoo.jpg">
						<p>Michael Yoo</p>
					</div>
					<div style="float:left; width:28.5%">
						<img src="https://web.duke.edu/mind/level2/faculty/pearson/assets/images/website/hayden.jpg" >
						<p>Ben Hayden</p>
					</div>
				</section>
				<section data-background-image="https://web.duke.edu/mind/level2/faculty/pearson/assets/images/ccn2017/4f.png">
					<div style="background-color: rgba(0, 0, 0, 0.75); padding: 10px" class="fragment fade-left">
						<h3>Why natural tasks?</h3>
						<ul>
							<li class="fragment">
								Selection pressure determines function
							</li>
							<br>
							<li class="fragment">
								Study brain in normal operating regime
							</li>
							<br>
							<li class="fragment">
								Engage multiple brain systems simultaneously
							</li>
							<br>
					</div>

					<aside class="notes" data-markdown>
						- [upper left](https://thedrinkingbird.files.wordpress.com/2013/05/img_2476.jpg)
						- [upper right](http://seancrane.com/galleries/japan/) Sean Crane
						- [lower right](http://www.gettyimages.com/license/153234629): MOHD RASFAN/AFP/GettyImages
						- [lower right](https://commons.wikimedia.org/wiki/File:Baviaan2.JPG) Dick Mudde
					</aside>
				</section>
				<section data-background-image="https://web.duke.edu/mind/level2/faculty/pearson/assets/images/sfn2019/charles_pursuit.jpeg">
					<div style="background-color: rgba(0, 0, 0, 0.75); padding: 10px" class="fragment fade-left">
						<h3>Why pursuit?</h3>
						<ul>
							<li class="fragment">
								Canonical natural behavior
							</li>
							<br>
							<li class="fragment">
								Really several (looped) behaviors:
								<ul>
									<li>Target detection</li>
									<li>Target selection</li>
									<li>Strategy selection</li>
									<li>Motor planning</li>
									<li>Motor execution</li>
								</ul>
							</li>
							<br>
							<li class="fragment">
								Multiple intersecting optimal/empirical models
							</li>
							<br>
					</div>

					<aside class="notes" data-markdown>
					</aside>
				</section>
				<section>
					<h3>Simulated Multi-Prey Pursuit</h3>
					<div style="width: 100%; float: left">
						<img src="https://web.duke.edu/mind/level2/faculty/pearson/assets/videos/sfn2019/trial.gif" alt="" style="width: 120%">
					</div>
					<!-- <video width="200%" align="center" controls autoplay loop src="https://web.duke.edu/mind/level2/faculty/pearson/assets/videos/sfn2019/trial.gif" type="video/mp4">
						Your browser does not support the video tag.
					</video> -->
					<p class="ref">Yoo, Tu, Piantadosi, Hayden (<a href="https://www.biorxiv.org/content/10.1101/694604v1.abstract">Nat. Neuro, forthcoming</a>)</p>
					<aside class="notes" data-markdown>
					</aside>
				</section>
				<section>
					<h3>aka, Pacman</h3>
					<div style="width: 100%; float: left">
						<img src="https://web.duke.edu/mind/level2/faculty/pearson/assets/images/sfn2019/yoo_f1a.svg" alt="" style="background: white">
					</div>
					<p class="ref">Yoo, Tu, Piantadosi, Hayden (<a href="https://www.biorxiv.org/content/10.1101/694604v1.abstract">Nat. Neuro, forthcoming</a>)</p>
				</section>
				<section>
					<h3>Modeling tactics</h3>
					<img src="https://web.duke.edu/mind/level2/faculty/pearson/assets/images/sfn2019/yoo_f2a.svg" alt="" style="background: white; width: 70%">
					<p class="ref">Yoo, Tu, Piantadosi, Hayden (<a href="https://www.biorxiv.org/content/10.1101/694604v1.abstract">Nat. Neuro, forthcoming</a>)</p>
				</section>
				<section>
					<h3>Modeling <i>strategies</i></h3>
					<ul>
						<li>
							Can we go beyond kinematics?
						</li>
						<br>
						<li>
							Can we identify distinct strategies?
						</li>
						<br>
						<li>
							Can we detect changes of mind?
						</li>
					</ul>
				</section>
				<section>
					<h3>What do we want?</h3>
					<ul>
						<li>
							Capture complexities present in real data
						</li>
						<br>
						<li>
							Work in terms of interpretable constructs
						</li>
						<br>
						<li>
							Be able to generate realistic behavior
						</li>
					</ul>
				</section>
				<section>
					<h3>Penalty Shot</h3>
					<video width="70%" align="center" controls autoplay loop src="https://web.duke.edu/mind/level2/faculty/pearson/assets/videos/penaltyshot/sess130_new.mp4" type="video/mp4">
						Your browser does not support the video tag.
					</video>
					<p class="ref">Iqbal, Yin et al. (<a href="https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1006895">PLoS Comp Bio, 2019</a>)</p>
					<aside class="notes" data-markdown>
					  - two monkeys, shooter and goalie (shooter recorded)
					  - controlled by joysticks
					  - roles rotated, animals know each other
					  - repeated sessions
					  - rapidly learned, rich dynamics
					</aside>
				</section>
				<section>
					<h3>Generated trials</h3>
					<div style="width: 50%; float: left">
						<img src="https://web.duke.edu/mind/level2/faculty/pearson/assets/images/penaltyshot/paper_figs/real_traces.svg" alt="">
					</div>
					<div style="width: 50%; float: right">
						<img src="https://web.duke.edu/mind/level2/faculty/pearson/assets/images/penaltyshot/paper_figs/gen_traces.svg" alt="">
					</div>
					<p class="ref">Iqbal, Yin et al. (<a href="https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1006895">PLoS Comp Bio, 2019</a>)</p>
				</section>
				<section>
					<h3>How we do it</h3>
					<ul>
						<li>
							Borrow from control theory, time series
						</li>
						<br>
						<li>
							Goals (= controller set points) evolve in time
						</li>
						<br>
						<li>
							Each strategy is a set of goal dynamics
							<ul>
								<li>
									state includes positions, velocities of all agents
								</li>
								<li>
									dynamics depend (linearly) on state
								</li>
								<li>
									&asymp; (H)HMM transitions between strategies
								</li>
								<li>
									transitions depend <i>nonlinearly</i> on state
								</li>
							</ul>
						</li>
						<br>
						<li>
							Variational Bayesian inference
						</li>
					</ul>
				</section>
				<section>
					<h3>Goal-based dynamical systems</h3>
					<video width="70%" align="center" controls autoplay loop src="https://web.duke.edu/mind/level2/faculty/pearson/assets/videos/penaltyshot/real_trial_goals.mp4" type="video/mp4">
						Your browser does not support the video tag.
					</video>
					<p class="ref">Iqbal, Yin et al. (<a href="https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1006895">PLoS Comp Bio, 2019</a>)</p>
				</section>

				<section>
					<h3>How do we compare to...</h3>
					<ul>
						<li>LFADS (Pandarinath et al., 2018)</li>
						<ul>
							<li>
								Less dimension reduction, more trajectory labeling
							</li>
							<li>
								Discrete, not continuous latents
							</li>
							<li>
								Coevolving exogenous inputs
							</li>
						</ul>
						<br>
						<li>
							rSLDS (Linderman et al., 2017; Nassar et al., 2019)
							<ul>
								<li>
									Variational, not MCMC (scale to larger data)
								</li>
								<li>
									Gumbel-softmax latents extend to <i>hierarchical</i> HMM
								</li>
							</ul>
						</li>
						<br>
					</ul>
				</section>
				<section>
					<h3>We can predict control</h3>
					<div style="width: 100%; float: left">
						<img src="https://web.duke.edu/mind/level2/faculty/pearson/assets/images/sfn2019/pacman_u_fits.svg" alt="" style="width: 120%">
					</div>
				</section>
				<section>
					<h3>We can infer latent goals</h3>
					<div style="width: 100%; float: left">
						<img src="https://web.duke.edu/mind/level2/faculty/pearson/assets/videos/sfn2019/trial_with_goal.gif" alt="" style="width: 120%">
					</div>
				</section>
				<section>
					<h3>We can label strategies</h3>
					<div style="width: 100%; float: left">
						<img src="https://web.duke.edu/mind/level2/faculty/pearson/assets/videos/sfn2019/trial_gmm.gif" alt="" style="width: 120%">
					</div>
				</section>
				<section>
					<h3>What's next?</h3>
					<ul>
						<li>Hierarchies of trial labels</li>
						<br>
						<li>Predator avoidance dynamics</li>
						<br>
						<li>Comparison with neural changepoints</li>
					</ul>
				</section>

				<section>
					<div class="wrapper" style="">
						<img
						class="grid-item"
						src="https://web.duke.edu/mind/level2/faculty/pearson/assets/images/website/kelsey.jpg"
						style="grid-column: 1/2">
						<img
						class="grid-item"
						src="https://web.duke.edu/mind/level2/faculty/pearson/assets/images/website/sam.jpg"
						style="grid-column: 2/3">
						<img
						class="grid-item"
						src="https://pearsonlab.github.io/images/anne.jpg"
						style="grid-column: 3/4">
						<img
						class="grid-item"
						src="https://pearsonlab.github.io/images/jack.jpg"
						style="grid-column: 4/5">
						<img
						class="grid-item"
						src="https://pearsonlab.github.io/images/pranjal.jpg"
						style="grid-column: 1/2">
						<img
						class="grid-item"
						src="https://web.duke.edu/mind/level2/faculty/pearson/assets/images/lab_logo/plab_logo_light.svg"
						style="grid-column: 2/4">
						<img
						class="grid-item"
						src="https://pearsonlab.github.io/images/nayoung.jpg"
						style="grid-column: 4/5">
						<img
						class="grid-item"
						src="https://pearsonlab.github.io/images/seth.jpg"
						style="grid-column: 1/2">
						<img
						class="grid-item"
						src="https://web.duke.edu/mind/level2/faculty/pearson/assets/images/website/syoo.jpg"
						style="grid-column: 2/3">
						<img
						class="grid-item"
						src="https://web.duke.edu/mind/level2/faculty/pearson/assets/images/website/hayden.jpg"
						style="grid-column: 3/4">
						<img
						class="grid-item"
						src="https://pearsonlab.github.io/images/kevin.jpg"
						style="grid-column: 4/5">
					</div>
				</section>
			</div>
		</div>

		<script src="lib/js/head.min.js"></script>
		<script src="js/reveal.js"></script>

		<script>
			// More info https://github.com/hakimel/reveal.js#configuration
			Reveal.initialize({
				history: true,
				// math: {
				//         mathjax: 'https://cdn.mathjax.org/mathjax/latest/MathJax.js',
				//         config: 'TeX-AMS_HTML-full'  // See http://docs.mathjax.org/en/latest/config-files.html
			    // },

				// More info https://github.com/hakimel/reveal.js#dependencies
				dependencies: [
					{ src: 'plugin/markdown/marked.js' },
					{ src: 'plugin/markdown/markdown.js' },
					{ src: 'plugin/notes/notes.js', async: true },
					{ src: 'plugin/math/math.js', async: true },
					{ src: 'plugin/highlight/highlight.js', async: true, callback: function() { hljs.initHighlightingOnLoad(); } }
				]
			});
		</script>
	</body>
</html>
